{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.array([3, 4])\n",
    "# dato un vettore u possiamo calcolare il suo modulo con\n",
    "np.linalg.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6, 0.8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la direzione di un vettore la chiamo w\n",
    "# è a sua volta un vettore con dimensioni (u1/u, u2/u)\n",
    "# posso calcolare anche questa\n",
    "w = u / np.linalg.norm(u) # perchè è un array numpy e non python\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([3, 4])\n",
    "y = np.array([6, 7]) \n",
    "np.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1d = point\n",
    "# 2d = line\n",
    "# 3d = plane\n",
    "# 4d> = hyperplane\n",
    "# un hyperplane ha una dimensione minore dello spazio, ad es. se lo spazio è 4 dimensioni, l'hyperplane ne ha 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad esempio se consideriamo una retta, la sua equazione è y = ax+b, se x=x1 e y=x2, ax1-x2+b = 0\n",
    "# sappiamo che x(x1, x2) e w(a, -1) quindi possiamo riscrivere l'equazione con una nuova forma:\n",
    "# wx + b = 0, questa equazione è molto utile perchè può essere usata per vettori n-dimensionali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se wx + b > 0 allora il dato apparterrà alla classe +\n",
    "# se wx + b < 0 allora il dato apparterrà alla classe -\n",
    "# infine se wx + b = 0 allora il dato apparterrà sarà sul confine di separazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se invece metto anzichè > o < di 0, > 1 o < -1, allora indico i punti che fanno parte di una classe e in più sono\n",
    "# oltre il supporto al vettore, ovvero il punto della classe più vicino all'iperpiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posso non ammettere nessuna misclassification, quindi l'hyperplane sarà sempre a metà tra i due estremi delle classi\n",
    "# questo modello prende il nome di 'Maximum Margin Classifier', ma soffre molto gli outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quindi conviene ammettere la misclassification, ovvero abbassare il bias e permettere che\n",
    "# qualche dato di train non venga classificato correttamente per alzare poi il valore della variance\n",
    "# in questo caso la distanza tra la linea di separazione e il dato della classe viene a chiamarsi 'soft margin'\n",
    "# i dati che fanno da confine e quelli che si trovano dentro sono chiamati 'support vectors'\n",
    "# per questo motivo il modello che utilizza soft margins si chiama 'Support Vector Classifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrano in gioco 'Support Vector Machines'\n",
    "# ad esempio se ho solo una dimensione, ma con i due metodi precedenti non funziona a causa della disposizione dei dati\n",
    "# dispongo i dati in uno spazio a due dimensioni, con sulla x i dati e sulla y i dati al quadrato\n",
    "# in questo modo posso usare come confine di separazione una linea e così riesco a classificare\n",
    "# in generale l'idea dietro al support vector machine è quella di iniziare con dei dati a basse dimensioni\n",
    "# successivamente aumentare le dimensioni e trovare un support vector classifier che funzioni bene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i support vector machines usano le funzioni kernel per trovare dei support vector classifier\n",
    "# così facendo sa se usare i dati elevati al quadrato e non per esempio al cubo o moltiplicati per due o ...\n",
    "# alcuni kernel sono: polinomial kernel, che ha un valore di d ovvero di dimensioni e con la cross validation\n",
    "# trova il migliore\n",
    "# un altro kernel è il radial kernel, anche conosciuto come radial basis function kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i kernel non applicano effettivamente la trasformazione dei dati per calcolare quale sia il migliore\n",
    "# ma si limitano a calcolare le varie relazione se i dati fossero trasformati così\n",
    "# questo trucco è chiamato 'kernel trick'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bit164af38e2bcc47a2b21e3548f92575a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
